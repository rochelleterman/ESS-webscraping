---
title: "Manipulating Data with `dplyr`"
subtitle: "3I: Webcraping & Data Management in R"
author: "Rochelle Terman"
date: "August 2020"
output:
  prettydoc::html_pretty:
    theme: hpstr
    highlight: github
---


# Collecting Data from the Web

## Introduction

There's a ton of web data that's useful to social scientists, including:

* social media
* news media
* government publications
* organizational records

There are two ways to get data off the web:

1. **[Web APIs]** - i.e. application-facing, for computers
2. **[Webscraping]** - i.e. user-facing websites for humans

__Rule of Thumb__: Check for API first. If not available, scrape.

## Web APIs 

API stands for **Application Programming Interface**. Broadly defined, an API is a set of rules and procedures that facilitate interactions between computers and their applications.

A very common type of API is the __Web API__, which (among other things) allows users to query a remote database over the internet.

Web APIs take on a variety of formats, but the vast majority adhere to a particular style known as **Reperesentational State Transfer** or **REST**. What makes these "RESTful" APIs so convenient is that we can use them to query databases using URLs. 

#### RESTful Web APIs are All Around You... {-}

Consider a simple Google search:

```{r echo = F}
knitr::include_graphics(path = "img/google_search.png")
```

Ever wonder what all that extra stuff in the address bar was all about?  In this case, the full address is Google's way of sending a query to its databases requesting information related to the search term "golden state warriors". 

```{r echo = F}
knitr::include_graphics(path = "img/google_link.png")
```

In fact, it looks like Google makes its query by taking the search terms, separating each of them with a "+", and appending them to the link "https://www.google.com/#q=".  Therefore, we should be able to actually change our Google search by adding some terms to the URL and following the general format...  

```{r echo = F}
knitr::include_graphics(path = "img/google_link_change.png")
```

Learning how to use RESTful APIs is all about learning how to format these URLs so that you can get the response you want.

### Some Basic Terminology

Let's get on the same page with some basic terminology:

* **Uniform Resource Location (URL)**: a string of characters that, when interpreted via the Hypertext Transfer Protocol (HTTP), points to a data resource, notably files written in Hypertext Markup Language (HTML) or a subset of a database. This is often referred to as a "call".

* **HTTP Methods/Verbs**:

    + *GET*: requests a representation of a data resource corresponding to a particular URL.  The process of executing the GET method is often referred to as a "GET request" and is the main method used for querying RESTful databases.
    
    + *HEAD*, *POST*, *PUT*, *DELETE*: other common methods, though mostly never used for database querying.
    
### How Do GET Requests Work? 

#### A Web Browsing Example {-}

As you might suspect from the example above, surfing the web is basically equivalent to sending a bunch of `GET` requests to different servers and asking for different files written in HTML.

Suppose, for instance, I wanted to look something up on Wikipedia.  My first step would be to open my web browser and type in http://www.wikipedia.org.  Once I hit return, I'd see the page below.  

```{r echo = F}
knitr::include_graphics(path = "img/wikipedia.png")
```

Several different processes occured, however, between me hitting "return" and the page finally being rendered.  In order:

1. The web browser took the entered character string and used the command-line tool "Curl" to write a properly formatted HTTP GET request and submitted it to the server that hosts the Wikipedia homepage.

2. After receiving this request, the server sent an HTTP response, from which Curl extracted the HTML code for the page (partially shown below).

3. The raw HTML code was parsed and then executed by the web browser, rendering the page as seen in the window.

```{r, echo=FALSE}
wiki<-httr::GET(url = "http://www.wikipedia.org")
body<-httr::content(x = wiki, as = "text")
substr(x = body, start = 1, stop = 1000)
```

#### Web Browsing as a Template for RESTful Database Querying {-}

The process of web browsing described above is a close analogue for the process of database querying via RESTful APIs, with only a few adjustments:

1. While the Curl tool will still be used to send HTML GET requests to the servers hosting our databases of interest, the character string that we supply to Curl must be constructed so that the resulting request can be interpreted and succesfully acted upon by the server.  In particular, it is likely that the character string must encode **search terms and/or filtering parameters**, as well as one or more **authentication codes**.  While the terms are often similar across APIs, most are API-specific.

2. Unlike with web browsing, the content of the server's response that is extracted by Curl is unlikely to be HTML code.  Rather, it will likely be **raw text response that can be parsed into one of a few file formats commonly used for data storage**.  The usual suspects include .csv, .xml, and .json files.

3. Whereas the web browser capably parsed and executed the HTML code, **one or more facilities in R, Python, or other programming languages will be necessary for parsing the server response and converting it into a format for local storage** (e.g. matrices, dataframes, databases, lists, etc.).

### Finding APIs

More and more APIs pop up every day. [Programmable Web](https://www.programmableweb.com/apis/directory) offers a running list of APIs. [This list](https://ucsd.libguides.com/c.php?g=90743&p=3202435) provides a list of APIs that may be useful to Political Scientists.

Here are some APIs that may be useful to you:

- [NYT Article API](http://developer.nytimes.com/): Provides metdata (title, summaries, dates, etc) from all New York Times articles in their archive.
- [GeoNames geographical database](https://www.geonames.org/): Provides lots of geographical information for all countries and other locations. The `geonames` package provides a wrapper for R.
- [The Manifesto Project](https://manifesto-project.wzb.eu/.): Provides text and other information on political party manifestos from around the world. It currently covers over 1000 parties from 1945 until today in over 50 countries on five continents. The `manifestoR` package provides a wrapper for R.
- [The Census Bureau](https://www.census.gov/developers/): Provides datasets from US Census Bureau. The `tidycensus` package allows users to interface with the US Census Bureauâ€™s decennial Census and five-year American Community APIs.

### Getting API Access

Most APIs requires a key or other user credentials before you can query their database. 

Getting credentialized with a API requires that you register with the organization. Most APIs are set up for developers, so you'll likely be asked to register an "application". All this really entails is coming up with a name for your app/bot/project, and providing your real name, organization, and email.  Note that some more popular APIs (e.g. Twitter, Facebook) will require additional information, such as a web address or mobile number.

Once you've successfully registered, you will be assigned one or more keys, tokens, or other credentials that must be supplied to the server as part of any API call you make. To make sure that users aren't abusing their data access privileges (e.g. by making many rapid queries), each set of keys will be given **rate limits** governing the total number of calls that can be made over certain intervals of time.  

For example, the NYT Article API has relatively generous rate limits --- 4,000 requests per day and 10 requests per minute. So we need to "sleep"" 6 seconds between calls to avoid hitting the per minute rate limit.


```{r echo = F}
knitr::include_graphics(path = "img/nytimes_key.png")
```

### Using APIs in R

There are two ways to collect data through APIs in R.

1. [**Plug-n-play packages**][Collecting Twitter Data with RTweet]

Many common APIs are available through user-written R Packages. These packages offer functions that "wrap" API queries and format the response. These packages are usually much more convenient than writing our own query, so it's worth searching around for a package that works with the API we need.

2. [**Writing our own API request**][Writing API Queries]

If no wrapper function is available, we have to write our own API request, and format the response ourselves using R. This is trickier, but definitely do-able.

